# docker-compose.yml
#
# This Docker Compose configuration file is used to deploy and manage multiple containerized services
# that enable Apache Airflow to run together with a PostgreSQL database. Apache Airflow is a workflow
# tool used to program, monitor, and manage workflows defined as code. This file defines several services
# needed for Apache Airflow to function properly in a containerized environment using Docker.
#
# The services defined in this file include:
#  - postgres: PostgreSQL database service that stores the metadata of Apache Airflow.
#  - airflow-init: Service to initialize the Airflow database with the necessary tables.
#  - webserver: Service that provides the Apache Airflow web interface to manage workflows (DAGs).
#  - scheduler: Service that manages the scheduling and execution of tasks defined in the Airflow DAGs.
#  - worker: Service that executes tasks scheduled by the scheduler using Celery.
#  - flower: Service that provides a web interface to monitor the Celery workers.
#
# Volumes:
#  - postgres-db-volume: A persistent volume that stores the data of the PostgreSQL database,
#    ensuring that the data is not lost when the container stops or is removed.
#
# Networks:
#  - airflow: A custom Docker network that allows communication between all the services
#    defined in this file.

version: '3'  # Version of the docker-compose file format.

services:

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      retries: 5
      timeout: 5s
    networks:
      - airflow

  airflow-init:
    image: apache/airflow:2.5.1
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
    entrypoint: /bin/bash -c "airflow db init"
    networks:
      - airflow

  webserver:
    image: apache/airflow:2.5.1
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__WEBSERVER__RBAC: "True"
      AIRFLOW__WEBSERVER__SECRET_KEY: "0506"
    ports:
      - "8080:8080"
    command: "airflow webserver"
    networks:
      - airflow
    volumes:
      - /home/lourdes22/data-pipeline/dags:/opt/airflow/dags
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health"]
      interval: 10s
      retries: 5
      timeout: 5s

  scheduler:
    image: apache/airflow:2.5.1
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__WEBSERVER__SECRET_KEY: "0506"
    command: "airflow scheduler"
    networks:
      - airflow
    volumes:
      - /home/lourdes22/data-pipeline/dags:/opt/airflow/dags
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob"]
      interval: 10s
      retries: 5
      timeout: 5s

  worker:
    image: apache/airflow:2.5.1
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__WEBSERVER__SECRET_KEY: "0506"
    command: "airflow celery worker"
    networks:
      - airflow
    volumes:
      - /home/lourdes22/data-pipeline/dags:/opt/airflow/dags
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type LocalTaskJob"]
      interval: 10s
      retries: 5
      timeout: 5s

  flower:
    image: apache/airflow:2.5.1
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    command: "airflow celery flower"
    ports:
      - "5555:5555"
    networks:
      - airflow

volumes:
  postgres-db-volume:
    driver: local

networks:
  airflow:
    driver: bridge